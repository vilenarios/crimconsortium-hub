# CrimRxiv Archive - Simplified Workflow

## Overview

This is the SIMPLIFIED workflow that replaces the previous complicated approach.

## Architecture

```
data/
├── sqlite/crimrxiv.db          ← Metadata + manifest_tx_id
├── articles/                    ← ALL content (generated by import)
│   ├── {slug}/
│   │   ├── metadata.json       ← Latest version metadata
│   │   ├── content.json        ← Latest version content
│   │   ├── article.md          ← Latest version markdown
│   │   ├── attachments/        ← Latest version attachments
│   │   │   └── paper.pdf       ← PDF or other media
│   │   ├── versions.json       ← Manifest of all versions
│   │   ├── 1/                  ← Release 1 (full content)
│   │   │   ├── metadata.json
│   │   │   ├── content.json
│   │   │   ├── article.md
│   │   │   └── attachments/
│   │   ├── 2/                  ← Release 2 (full content)
│   │   │   └── ...
│   │   └── ...
│   └── ...
└── export/
    └── metadata.parquet         ← Browser-optimized metadata
```

## The 5-Step Workflow

### Step 1: Import from CrimRxiv
```bash
npm run import
```

**What it does:**
- Scrapes CrimRxiv.com using PubPub SDK
- Saves EVERYTHING to `data/articles/{slug}/`:
  - Root level: Latest version (metadata.json, content.json, article.md, attachments/)
  - Version folders: All releases (1/, 2/, 3/... each with full content)
  - versions.json: Manifest of all versions
- Saves metadata to SQLite (for querying)
- Fetches all historical versions/releases for each article

**Output:**
- `data/articles/` folder with 3,700+ article folders
- `data/sqlite/crimrxiv.db` database with metadata

**Time:** 30-45 minutes (full import)

---

### Step 2: Export to Parquet
```bash
npm run export
```

**What it does:**
- Reads metadata from SQLite
- Exports to `data/export/metadata.parquet`
- Includes `manifest_tx_id` references (if available)

**Output:**
- `data/export/metadata.parquet` (~5 MB)

**Time:** ~30 seconds

---

### Step 3: Upload Articles to Arweave
```bash
npm run upload:articles
```

**What it does:**
- Reads all folders in `data/articles/`
- Uses ArDrive Turbo SDK `uploadFolder()` method
- Uploads each article folder
- **Automatically creates manifest for each folder**
- Gets manifest TX ID for each article
- **Updates SQLite** with `manifest_tx_id`

**Output:**
- Each article uploaded to Arweave
- Manifest TX IDs saved in SQLite

**Time:** 2-4 hours (for 3,700+ articles)

**Cost:** ~$10-15 in AR tokens

---

### Step 4: Re-Export Parquet (with TX IDs)
```bash
npm run export
```

**What it does:**
- Re-exports parquet with `manifest_tx_id` values
- Now articles have references to their Arweave manifests

**Output:**
- Updated `data/export/metadata.parquet` with TX IDs

**Time:** ~30 seconds

---

### Step 5: Upload Parquet + Update ArNS

```bash
npm run upload:parquet
```

**What it does:**
- Uploads `metadata.parquet` to Arweave
- **Automatically updates ArNS undername** to point to new TX ID
- Makes data available at: `https://data_{name}.arweave.net/metadata.parquet`

**Required .env variables:**
- `ARNS_ROOT_NAME` - Your ArNS name (e.g., "crimrxiv")
- `ARNS_DATA_UNDERNAME` - Undername for data (default: "data")
- `ARNS_PROCESS_ID` - ANT process ID from arns.app

**Output:**
- Parquet TX ID
- ArNS record updated automatically ✅

**Time:** ~2 minutes
**Cost:** ~$0.10 in AR tokens

---

### Step 6: Build & Deploy App

```bash
# Upload WASM files (first time only)
npm run upload:wasm

# Build app
npm run build

# Deploy app to Arweave
npm run sync

# Manually update root ArNS record @ → app TX ID
# (via arns.app or AR.IO SDK)
```

**What it does:**
- Uploads DuckDB WASM files (first time only)
- Builds SPA to `dist/` folder
- Deploys app to Arweave
- Gets app TX ID

**Output:**
- Live site on Arweave!

**Time:** ~5 minutes
**Cost:** ~$0.50 in AR tokens

---

## Testing Locally

### Before Upload
```bash
npm run import          # Import data
npm run export          # Export parquet
npm run build           # Build app
npm run preview         # Test at http://localhost:4174
```

**What works:**
- Homepage shows articles from parquet
- Search works
- Articles show metadata (no content yet, since not uploaded)

### After Upload
```bash
npm run preview         # Test at http://localhost:4174
```

**What works:**
- Everything!
- Articles load full content from local manifests
- PDFs download

---

## Data Flow

```
Step 1: CrimRxiv.com
           ↓ (PubPub SDK)
Step 2: data/articles/{slug}/
           ├── metadata.json
           ├── content.json
           ├── article.md
           └── pdfs/*.pdf
           ↓
Step 3: SQLite (metadata only)
           ↓
Step 4: data/export/metadata.parquet
           ↓
Step 5: Upload to Arweave
           ├── Article folders → Manifest TX IDs
           ├── Parquet file → Parquet TX ID
           └── WASM files → WASM TX IDs
           ↓
Step 6: Configure ArNS
           ├── data_crimrxiv.arweave.net → Parquet TX ID
           └── crimrxiv.arweave.net → App TX ID
```

---

## File Sizes

| Item | Size | Notes |
|------|------|-------|
| `data/articles/` | ~200 MB | All content + PDFs |
| `data/sqlite/crimrxiv.db` | ~50 MB | Metadata only |
| `data/export/metadata.parquet` | ~5 MB | Browser-optimized |
| App bundle | ~1 MB | JavaScript + HTML |
| WASM files | ~72 MB | Uploaded once |

---

## Update Workflow

When CrimRxiv publishes new articles:

```bash
# 1. Re-import (incremental, fast)
npm run import

# 2. Upload only new articles
npm run upload:articles  # Skips existing

# 3. Re-export parquet
npm run export

# 4. Upload new parquet
npm run upload:parquet

# 5. Update ArNS (point to new parquet TX ID)
```

**No need to rebuild or redeploy the app!**

---

## Costs

| Operation | Cost (approx) | Frequency |
|-----------|---------------|-----------|
| Initial article upload (3,700) | ~$15 | One-time |
| Parquet upload | ~$0.50 | Per update |
| WASM upload | ~$7 | One-time |
| App deploy | ~$0.10 | Per app update |

Total first deployment: ~$22
Subsequent data updates: ~$0.50 (parquet only)

---

## Troubleshooting

### Import fails
- Check `.env` has `PUBPUB_EMAIL` and `PUBPUB_PASSWORD`
- Verify internet connection
- Check CrimRxiv.com is accessible

### Upload fails
- Check `.env` has `ARWEAVE_WALLET_PATH`
- Verify wallet has sufficient AR balance
- Check wallet file exists and is valid JSON

### Preview shows no articles
- Run `npm run export` to generate parquet
- Check `data/export/metadata.parquet` exists
- Verify SQLite has data

### Articles show no content
- Manifests not uploaded yet (run `npm run upload:articles`)
- Or local testing before upload (expected behavior)

---

## Benefits of This Workflow

✅ **Simple:** 5 clear steps
✅ **Fast:** Import is incremental, export is 30 seconds
✅ **Organized:** All content in `data/articles/`
✅ **Automatic:** Manifests created automatically by Turbo SDK
✅ **Efficient:** Only upload new/changed articles
✅ **Cost-effective:** Pay only for new data
✅ **Maintainable:** Easy to understand and debug

---

## Previous Approach (Deprecated)

The old workflow had:
- Separate manifest generation script
- Manual manifest creation
- Complex upload process
- Scattered files

All of that is GONE! The new workflow is much simpler.

---

## Questions?

See:
- `CLAUDE.md` - Full development guide
- `DEPLOYMENT_GUIDE.md` - Detailed deployment steps
- `TESTING_CHECKLIST.md` - Testing procedures

---

**Last Updated:** 2025-11-02
**Status:** ✅ Simplified and ready to use!
